{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='Yellow'>Scrapping Indeed.com data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10'\n",
    "# URL='https://www.indeed.co.in/data-scientist-jobs-in-Bengaluru,-Karnataka'\n",
    "##conducting a request of the stated URL above:\n",
    "\n",
    "\n",
    "header = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\", \"X-Requested-With\": \"XMLHttpRequest\"}\n",
    "page = requests.get(URL)#,verify=False)\n",
    "#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "#printing soup in a more structured tree format that makes for easier reading\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Machine Learning Engineer',\n",
       " 'Sr. Data Scientist',\n",
       " 'Data Scientist (NLP Focused)',\n",
       " 'Data Science/ML engineer with specialty in NLP',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Machine learning intern and Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist (BCMA)',\n",
       " 'Data Analyst / Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Sr. Data Analyst']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "#         print(div)\n",
    "      for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "#           print(a)\n",
    "          jobs.append(a['title'])\n",
    "    return(jobs)\n",
    "extract_job_title_from_result(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 1\n",
      "Engel & Völkers Americas, Inc.\n",
      "16 1\n",
      "Triplebyte\n",
      "13 1\n",
      "Ascensia Diabetes Care\n",
      "14 1\n",
      "Fakespot\n",
      "16 1\n",
      "Transport Learning\n",
      "11 1\n",
      "Source Enterprises\n",
      "11 1\n",
      "PepsiCo\n",
      "11 1\n",
      "Kaplan\n",
      "12 1\n",
      "Behold.ai\n",
      "11 1\n",
      "StreetEasy\n",
      "11 1\n",
      "Cornell University\n",
      "11 1\n",
      "LOCKHEED MARTIN CORPORATION\n",
      "11 1\n",
      "CITI\n",
      "11 1\n",
      "Defined Clarity\n",
      "15 1\n",
      "Strategic Financial Solutions\n",
      "13 1\n",
      "Noom Inc.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Engel & Völkers Americas, Inc.',\n",
       " 'Triplebyte',\n",
       " 'Ascensia Diabetes Care',\n",
       " 'Fakespot',\n",
       " 'Transport Learning',\n",
       " 'Source Enterprises',\n",
       " 'PepsiCo',\n",
       " 'Kaplan',\n",
       " 'Behold.ai',\n",
       " 'StreetEasy',\n",
       " 'Cornell University',\n",
       " 'LOCKHEED MARTIN CORPORATION',\n",
       " 'CITI',\n",
       " 'Defined Clarity',\n",
       " 'Strategic Financial Solutions',\n",
       " 'Noom Inc.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_company_from_result(soup): \n",
    "    companies = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "#         print(len(div))\n",
    "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "        print(len(div),len(company))\n",
    "#         print(company)\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "                print(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "            for span in sec_try:\n",
    "              companies.append(span.text.strip())\n",
    "    return(companies)\n",
    " \n",
    "extract_company_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['New York, NY',\n",
       " 'New York, NY',\n",
       " 'Valhalla, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'Ithaca, NY',\n",
       " 'Rochester, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY',\n",
       " 'New York, NY']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[]\n",
    "for div in soup.find_all(name='div', attrs={'class':'recJobLoc'}):\n",
    "#     print(len(div['data-rc-loc']))\n",
    "    a.append(div['data-rc-loc'])\n",
    "    \n",
    "    \n",
    "print(len(a))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York, NY\n",
      "New York, NY 10017 (Murray Hill area)\n",
      "New York, NY 10019\n",
      "New York, NY\n",
      "New York, NY 10002\n",
      "Ithaca, NY 14853\n",
      "Rochester, NY 14623\n",
      "New York, NY\n",
      "New York, NY\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for div in soup.find_all(name='span', attrs={'class':'location'}):\n",
    "    print(div.text)\n",
    "    i=i+1\n",
    "    \n",
    "print(i)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_location_from_result(soup): \n",
    "  locations = []\n",
    "  spans = soup.findAll('span', attrs={'class':'location'})\n",
    "  for span in spans:\n",
    "    locations.append(span.text)\n",
    "  return(len(locations))\n",
    "extract_location_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engel & Völkers Americas, Inc.\n",
      "Triplebyte\n",
      "*****\n",
      "<span class=\"salary no-wrap\">\n",
      "<span class=\"salaryText\">\n",
      "$125,000 - $190,000 a year</span>\n",
      "</span>\n",
      "*****\n",
      "data: $125,000 - $190,000 a year\n",
      "Ascensia Diabetes Care\n",
      "Fakespot\n",
      "Transport Learning\n",
      "*****\n",
      "<span class=\"salary no-wrap\">\n",
      "<span class=\"salaryText\">\n",
      "$80,000 - $150,000 a year</span>\n",
      "</span>\n",
      "*****\n",
      "data: $80,000 - $150,000 a year\n",
      "Source Enterprises\n",
      "PepsiCo\n",
      "Kaplan\n",
      "Behold.ai\n",
      "StreetEasy\n",
      "Cornell University\n",
      "LOCKHEED MARTIN CORPORATION\n",
      "CITI\n",
      "Defined Clarity\n",
      "Strategic Financial Solutions\n",
      "Noom Inc.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['$125,000 - $190,000 a year', '$80,000 - $150,000 a year']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_salary_from_result(soup): \n",
    "  salaries = []\n",
    "  for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "#         print(div.text)\n",
    "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "                print(b.text.strip())\n",
    "                \n",
    "           \n",
    "            for link in div.find_all(name=\"span\", attrs={\"class\":\"salary\"}):\n",
    "                print(\"\"\"*****\"\"\")\n",
    "                print(link)\n",
    "                print(\"\"\"*****\"\"\")\n",
    "                print(\"data:\", link.text.strip())\n",
    "\n",
    "                if link.text.strip() != '':\n",
    "                    salaries.append(link.text.strip())\n",
    "                else:\n",
    "                    try:\n",
    "                        div_two = div.find(name=\"span\", attrs={\"class\":\"salary\"})\n",
    "                        div_three = div_two.find(\"div\")\n",
    "                        salaries.append(div_three.text.strip())\n",
    "#                         salaries.append(\"Nothing_found\")\n",
    "\n",
    "                    except:\n",
    "                        salaries.append(\"Nothing_found\")\n",
    "        #         print(link)\n",
    "        else:\n",
    "            print(\"None\")\n",
    "              \n",
    "                \n",
    "                \n",
    "  return(salaries)\n",
    "extract_salary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Engel & Völkers Americas, Inc.\\n\\n\\n\\n3.9',\n",
       " 'Triplebyte',\n",
       " 'Ascensia Diabetes Care\\n\\n\\n\\n3.7',\n",
       " 'Fakespot',\n",
       " 'Transport Learning',\n",
       " 'Source Enterprises\\n\\n\\n\\n5.0',\n",
       " 'PepsiCo\\n\\n\\n\\n3.8',\n",
       " 'Kaplan\\n\\n\\n\\n3.7',\n",
       " 'Behold.ai',\n",
       " 'StreetEasy\\n\\n\\n\\n3.8',\n",
       " 'Cornell University\\n\\n\\n\\n4.3',\n",
       " 'LOCKHEED MARTIN CORPORATION\\n\\n\\n\\n4.0',\n",
       " 'CITI\\n\\n\\n\\n3.9',\n",
       " 'Defined Clarity',\n",
       " 'Strategic Financial Solutions\\n\\n\\n\\n3.5',\n",
       " 'Noom Inc.\\n\\n\\n\\n4.0']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salrie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ Company :: Salaries }\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Engel & Völkers Americas, Inc.': 'Nothing found',\n",
       " 'Triplebyte': '$125,000 - $190,000 a year',\n",
       " 'Ascensia Diabetes Care': 'Nothing found',\n",
       " 'Fakespot': 'Nothing found',\n",
       " 'Transport Learning': '$80,000 - $150,000 a year',\n",
       " 'Source Enterprises': 'Nothing found',\n",
       " 'PepsiCo': 'Nothing found',\n",
       " 'Kaplan': 'Nothing found',\n",
       " 'Behold.ai': 'Nothing found',\n",
       " 'StreetEasy': 'Nothing found',\n",
       " 'Cornell University': 'Nothing found',\n",
       " 'LOCKHEED MARTIN CORPORATION': 'Nothing found',\n",
       " 'CITI': 'Nothing found',\n",
       " 'Defined Clarity': 'Nothing found',\n",
       " 'Strategic Financial Solutions': 'Nothing found',\n",
       " 'Noom Inc.': 'Nothing found'}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_salary(soup):\n",
    "    li=[]\n",
    "    salaries=[]\n",
    "    compaines=[]\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "    #     print(div)\n",
    "        li.append(div)\n",
    "    #     print(type(div))\n",
    "#         print('####$$$$$$$$$####')\n",
    "#         print(len(div.find_all(name=\"span\", attrs={\"class\":\"salary\"})))\n",
    "        if len(div.find_all(name=\"span\", attrs={\"class\":\"salary\"})) ==0:\n",
    "            salaries.append(\"Nothing found\")\n",
    "        else:\n",
    "\n",
    "            for div_two in div.find_all(name=\"span\", attrs={\"class\":\"salary\"}):\n",
    "        #     div_three = div_two.find('div')\n",
    "\n",
    "        #     print(div_two.find_all(name=\"span\", attrs={\"class\":\"salaryText\"}))\n",
    "#                 print(div_two.text.strip())\n",
    "#                 print(type(div_two.text.strip()))\n",
    "                salaries.append(div_two.text.strip())\n",
    "    #             if type(div_two.text.strip()) == '':\n",
    "    #                 print(\"Null\")\n",
    "        #         print(div_two.text.strip())\n",
    "\n",
    "        #     asd=div_two.find_all(name=\"span\", attrs={\"class\":\"salaryText\"})\n",
    "        #     print(type(div_two))\n",
    "        #     if str(div_two) == []:\n",
    "        #         print('Nolee')\n",
    "#         print('####$$$$$$$$$####')\n",
    "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "#         print(len(div),len(company))\n",
    "    #         print(company)\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "    #             print(b.text.strip())\n",
    "    #     link=div.find_all(name=\"span\", attrs={\"class\":\"salary\"})\n",
    "    #     print(link)\n",
    "\n",
    "\n",
    "    #     if True:\n",
    "    #         break\n",
    "    #     link=div.find(name=\"span\", attrs={\"class\":\"salary\"})\n",
    "    #     for span in div.find_all('span', recursive=False):\n",
    "    #             print('jkds')\n",
    "    #         print span.attrs['title']\n",
    "    #     print(link)\n",
    "    #         print(link)\n",
    "    #         company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "\n",
    "    # li[3]\n",
    "    print('{ Company :: Salaries }')\n",
    "    return (dict(zip(companies,salaries)))\n",
    "\n",
    "extract_salary(soup)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nothing found', '$125,000 - $190,000 a year', 'Nothing found', 'Nothing found', '$80,000 - $150,000 a year', 'Nothing found', 'Nothing found', 'Nothing found', 'Nothing found', 'Nothing found', 'Nothing found', 'Nothing found', 'Nothing found', 'Nothing found', 'Nothing found', 'Nothing found']\n",
      "['Engel & Völkers Americas, Inc.', 'Triplebyte', 'Ascensia Diabetes Care', 'Fakespot', 'Transport Learning', 'Source Enterprises', 'PepsiCo', 'Kaplan', 'Behold.ai', 'StreetEasy', 'Cornell University', 'LOCKHEED MARTIN CORPORATION', 'CITI', 'Defined Clarity', 'Strategic Financial Solutions', 'Noom Inc.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Engel & Völkers Americas, Inc.': 'Nothing found',\n",
       " 'Triplebyte': '$125,000 - $190,000 a year',\n",
       " 'Ascensia Diabetes Care': 'Nothing found',\n",
       " 'Fakespot': 'Nothing found',\n",
       " 'Transport Learning': '$80,000 - $150,000 a year',\n",
       " 'Source Enterprises': 'Nothing found',\n",
       " 'PepsiCo': 'Nothing found',\n",
       " 'Kaplan': 'Nothing found',\n",
       " 'Behold.ai': 'Nothing found',\n",
       " 'StreetEasy': 'Nothing found',\n",
       " 'Cornell University': 'Nothing found',\n",
       " 'LOCKHEED MARTIN CORPORATION': 'Nothing found',\n",
       " 'CITI': 'Nothing found',\n",
       " 'Defined Clarity': 'Nothing found',\n",
       " 'Strategic Financial Solutions': 'Nothing found',\n",
       " 'Noom Inc.': 'Nothing found'}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(salaries)\n",
    "print(companies)\n",
    "val=dict(zip(companies, salaries))\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"jobsearch-SerpJobCard unifiedRow row result\" data-ci=\"331337478\" data-empn=\"6746618955462657\" data-jk=\"6655bb6bd3cae41b\" id=\"pj_6655bb6bd3cae41b\">\n",
       "<style>\n",
       ".jobcard_logo{margin:6px 0}.jobcard_logo img{width:auto;max-width:80px;max-height:30px}\n",
       "</style>\n",
       "<div class=\"title\">\n",
       "<a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/pagead/clk?mo=r&amp;ad=-6NYlbfkN0CY-1pag0Birf9XWuMEmN9oBJkx32CeICH9Wk7A_CzAoWEkG-KTe2eTY1wvNMBRWna_ScaWe7S-cb0l8PB2za3UPhiSnvwcb37oqIh3kNPPB4wUMCT1_xEXxLIc6yrjKgPAcuv_GJi7isauhczVsHxOKzqgL7-qkd12V8BuKGyM1liueq4ycF6KCU8glzBvq79V73EqzPKNK5XvDpb7XbXcw0PhbSjQn202uqo_Cfwxbbu6ZinXhV26OGV_IOXnTyMHaSluzrk_V7Ncoa1kexZQXusazTKh7NC2FaogkXSXLu_cu0_ThCpcNd_ivSjR9nbpImko4nztMnxU_uM7xuCSVzhUWEXQy-jCARe3IjZD1tFpK4wF4g0lm3wrRI0-lGreWK7G7EXkXGABuhiKS1qduqCRAJV0CI-erd0X_ffpAmQa2BinlxWnedsr6dVQfjTDnBQqHE1ws2bWQmjs1B3d0YAd-8uuhMI=&amp;p=3&amp;fvj=1&amp;vjs=3\" id=\"sja3\" onclick=\"setRefineByCookie(['salest']); sjoc('sja3', 0); convCtr('SJ'); rclk(this,jobmap[3],true,0);\" onmousedown=\"sjomd('sja3'); clk('sja3'); rclk(this,jobmap[3],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist (NLP Focused)\">\n",
       "<b>Data</b> <b>Scientist</b> (NLP Focused)</a>\n",
       "</div>\n",
       "<div class=\"sjcl\">\n",
       "<div>\n",
       "<span class=\"company\">\n",
       "Fakespot</span>\n",
       "</div>\n",
       "<div class=\"recJobLoc\" data-rc-loc=\"New York, NY\" id=\"recJobLoc_6655bb6bd3cae41b\" style=\"display: none\"></div>\n",
       "<div class=\"location accessible-contrast-color-location\">New York, NY 10005 <span style=\"font-size: smaller\">(Financial District area)</span></div>\n",
       "</div>\n",
       "<table class=\"jobCardShelfContainer\"><tr class=\"jobCardShelf\"><td class=\"jobCardShelfItem\"><span class=\"iaLabel\">Easily apply</span></td></tr></table><div class=\"summary\">\n",
       "<ul style=\"list-style-type:circle;margin-top: 0px;margin-bottom: 0px;padding-left:20px;\"> <li style=\"margin-bottom:0px;\">Fakespot is looking for a data scientist to join our team on-site in our NYC office.</li><li>Fakespot is a review authentication service used by millions of users to…</li></ul></div>\n",
       "<div class=\"jobsearch-SerpJobCard-footer\">\n",
       "<div class=\"jobsearch-SerpJobCard-footerActions\">\n",
       "<div class=\"result-link-bar-container\">\n",
       "<div class=\"result-link-bar\"><span class=\"sponsoredGray\">Sponsored</span><span class=\"result-link-bar-separator hide-sponsored-separator\">·</span><span class=\"date\">6 days ago</span><span class=\"tt_set\" id=\"tt_set_3\"><span class=\"result-link-bar-separator\">·</span><a class=\"sl resultLink save-job-link\" href=\"#\" id=\"sj_6655bb6bd3cae41b\" onclick=\"changeJobState('6655bb6bd3cae41b', 'save', 'linkbar', true, ''); return false;\" title=\"Save this job to my.indeed\">Save job</a></span><div class=\"edit_note_content\" id=\"editsaved2_6655bb6bd3cae41b\" style=\"display:none;\"></div><script>if (!window['sj_result_6655bb6bd3cae41b']) {window['sj_result_6655bb6bd3cae41b'] = {};}window['sj_result_6655bb6bd3cae41b']['showSource'] = false; window['sj_result_6655bb6bd3cae41b']['source'] = \"Indeed\"; window['sj_result_6655bb6bd3cae41b']['loggedIn'] = false; window['sj_result_6655bb6bd3cae41b']['showMyJobsLinks'] = false;window['sj_result_6655bb6bd3cae41b']['undoAction'] = \"unsave\";window['sj_result_6655bb6bd3cae41b']['relativeJobAge'] = \"6 days ago\";window['sj_result_6655bb6bd3cae41b']['jobKey'] = \"6655bb6bd3cae41b\"; window['sj_result_6655bb6bd3cae41b']['myIndeedAvailable'] = true; window['sj_result_6655bb6bd3cae41b']['showMoreActionsLink'] = window['sj_result_6655bb6bd3cae41b']['showMoreActionsLink'] || false; window['sj_result_6655bb6bd3cae41b']['resultNumber'] = 3; window['sj_result_6655bb6bd3cae41b']['jobStateChangedToSaved'] = false; window['sj_result_6655bb6bd3cae41b']['searchState'] = \"q=data scientist $20,000&amp;l=New+York&amp;start=10\"; window['sj_result_6655bb6bd3cae41b']['basicPermaLink'] = \"https://www.indeed.com\"; window['sj_result_6655bb6bd3cae41b']['saveJobFailed'] = false; window['sj_result_6655bb6bd3cae41b']['removeJobFailed'] = false; window['sj_result_6655bb6bd3cae41b']['requestPending'] = false; window['sj_result_6655bb6bd3cae41b']['notesEnabled'] = false; window['sj_result_6655bb6bd3cae41b']['currentPage'] = \"serp\"; window['sj_result_6655bb6bd3cae41b']['sponsored'] = true;window['sj_result_6655bb6bd3cae41b']['showSponsor'] = true;window['sj_result_6655bb6bd3cae41b']['reportJobButtonEnabled'] = false; window['sj_result_6655bb6bd3cae41b']['showMyJobsHired'] = false; window['sj_result_6655bb6bd3cae41b']['showSaveForSponsored'] = true; window['sj_result_6655bb6bd3cae41b']['showJobAge'] = true; window['sj_result_6655bb6bd3cae41b']['showHolisticCard'] = true; window['sj_result_6655bb6bd3cae41b']['showDislike'] = false; window['sj_result_6655bb6bd3cae41b']['showKebab'] = false;</script></div></div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"tab-container\">\n",
       "<div class=\"sign-in-container result-tab\"></div>\n",
       "<div class=\"tellafriend-container result-tab email_job_content\"></div>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Founded in Hamburg, Germany in 1977, Engel & Völkers now includes over 750 brokerages in 34 countries across five continents.',\n",
       " \"Triplebyte is transforming the way software engineers are hired.Human decision making doesn't work at our scale; our marketplace is powered by automated…\",\n",
       " 'The ideal candidate will be intricately involved in running analytical experiments in a methodical manner and will regularly evaluate alternate models via…',\n",
       " 'Fakespot is looking for a data scientist to join our team on-site in our NYC office.Fakespot is a review authentication service used by millions of users to…',\n",
       " 'We are looking for a Data Scientist with strong NLP skills.The responsibilities include cleaning and classifying unstructured textual and media data.',\n",
       " 'Work with our industry experts to gain unrivaled knowledge at both the strategic level (generating bold and innovative ideas for data science-driven growth) and…',\n",
       " 'By focusing on machine learning and automation, the Data Science & Analytics group is pushing the bounds of possibility for PepsiCo and its strategic partners.',\n",
       " 'Kaplan Test Prep is hiring a Data Scientist!We are looking for individuals who love and excel at analyzing and visualizing data to solve important problems!',\n",
       " 'We are currently seeking outstanding interns to join our development team.Developers will work on the enhancement and maintenance of our data pipeline…',\n",
       " 'StreetEasy is seeking a dynamic data scientist focused on the confluence of product and marketing analytics.Analyze complex datasets (e.g., hit-level app data)…',\n",
       " 'Cornell University is seeking a full-time Data Scientist to assist the statistical consultants with the organization and analyses of data, preparation of…',\n",
       " \"RMS's Data Analytics Innovations (DAI) team applies technology, processes and expertise to a wide variety of platform data in order to drive proactive decision…\",\n",
       " 'The Data Science Senior Analyst is a seasoned professional role.Applies in-depth disciplinary knowledge, contributing to the development of new techniques and…',\n",
       " 'We have a client that is looking for a data scientist to add to its team.This position is for a Fortune 50 company that is based in Philadelphia.',\n",
       " 'Have you got a knack for solving problems?Strategic is looking for an experienced Data Scientist with statistical and machine learning experience to join our…',\n",
       " 'We are looking for a Sr. Data Analyst to join our Data team and help us perform complex analysis and modelling on our data warehouse.']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_summary_from_result(soup): \n",
    "  summaries = []\n",
    "  spans = soup.findAll('div', attrs={'class': 'summary'})\n",
    "  for span in spans:\n",
    "    summaries.append(span.text.strip())\n",
    "  return(summaries)\n",
    "extract_summary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
